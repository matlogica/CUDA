# AAD for CUDA Code

This project demonstrates how to integrate an operator overloading AAD (Automatic Differentiation) library, such as AADC, with existing CUDA code. This approach allows for efficient computational differentiation on both CPU and GPU using a unified code base.

## Key Features

- **Minimal Code Changes**: Incorporating AAD requires minimal adjustments to the existing CUDA code.
- **Unified Implementation**: A single CUDA implementation serves dual purposes:
  - GPU execution without AAD.
  - CPU execution with AAD.
- **Simplified Maintenance**: No need to maintain two versions of the same analytical code.
- **Type Flexibility**:
  - Use `idouble` for CPU code with AAD.
  - Use native `double` for GPU code.
- **Compiler Compatibility**: Compatible with major C++ compilers including G++, Clang, and Visual Studio.
- **Multi-threading and Vectorization**: AADC kernels can be executed on the CPU using multiple threads and vector instructions (AVX2/AVX512).

## Configuration Details

`nvcc` does not compile C++ code for the CPU; instead, it delegates this task to an underlying C++ compiler based on the user's choice (Visual Studio, GCC, or Clang). It's feasible to configure the C++ project to utilize active types on the CPU and native types on the GPU.

### NVCC Macros

- `__CUDACC__`: Indicates the code is being compiled by the CUDA compiler.
- `__CUDA_ARCH__`: Defined when compiling for the device, indicating the code is for GPU execution.

### Type Definitions for Flexibility

To enhance code clarity and manageability, it's recommended to use type aliases to distinguish between floating point calculations on different platforms. Here's an example of setting the `Real` type based on the compilation context:

```cpp
// Header to select the actual Real type based on host/device
#ifdef __CUDACC__
// This code is compiled by the CUDA compiler
#ifdef __CUDA_ARCH__
// GPU-specific code: __CUDA_ARCH__ is defined, so we are compiling for the device

typedef double Real;
#else
// CPU-specific code: __CUDA_ARCH__ is not defined, so we are compiling for the host

#include <aadc/idouble.h>
typedef idouble Real;
#endif
#endif
```

### Function Definitions

- `__global__` functions can only be called from the CPU and executed on the GPU. These functions cannot be recorded using AADC. Alternative approaches should be considered if recording is necessary.
- `__host__ __device__` functions can be called and executed on both CPU and GPU. The aim is to continue using native `double` on the GPU and active `idouble` type on the CPU.

#### Example Function

```cpp
// Analytics function callable from both CPU and GPU
__host__ __device__ void analytics(Real a, Real b, Real &c) {
    c = a * std::exp(std::sin(b));
}
```

### Calculation Execution

The `CALC()` function orchestrates calculations using either a CUDA kernel or an AADC kernel, utilizing the common `analytics` code. When executed via AADC, the kernel is capable of calculating sensitivities using AAD.

### Compilation

For visibility inspect compilation instructions in compile.sh

### Verbose output

```
#$ _NVVM_BRANCH_=nvvm
#$ _SPACE_= 
#$ _CUDART_=cudart
#$ _HERE_=/usr/lib/nvidia-cuda-toolkit/bin
#$ _THERE_=/usr/lib/nvidia-cuda-toolkit/bin
#$ _TARGET_SIZE_=
#$ _TARGET_DIR_=
#$ _TARGET_SIZE_=64
#$ NVVMIR_LIBRARY_DIR=/usr/lib/nvidia-cuda-toolkit/libdevice
#$ PATH=/usr/lib/nvidia-cuda-toolkit/bin:/home/username/.vscode-server/cli/servers/Stable-e7e037083ff4455cf320e344325dacb480062c3c/server/bin/remote-cli:/home/username/.cargo/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/username/.dotnet/tools
#$ LIBRARIES=  -L/usr/lib/x86_64-linux-gnu/stubs -L/usr/lib/x86_64-linux-gnu
#$ clang-14 -std=c++11 -D__CUDA_ARCH__=520 -D__CUDA_ARCH_LIST__=520 -E -x c++  -DCUDA_DOUBLE_MATH_FUNCTIONS -D__CUDACC__ -D__NVCC__  -march=core-avx2 -I"../../include/"  -D__CUDACC_VER_MAJOR__=11 -D__CUDACC_VER_MINOR__=8 -D__CUDACC_VER_BUILD__=89 -D__CUDA_API_VER_MAJOR__=11 -D__CUDA_API_VER_MINOR__=8 -D__NVCC_DIAG_PRAGMA_SUPPORT__=1 -include "cuda_runtime.h" -m64 "CALC.cu" -o "CALC.cpp1.ii" 
#$ cicc --c++11 --clang --clang_version=140000 --display_error_number --orig_src_file_name "CALC.cu" --orig_src_path_name "CUDA/CALC.cu" --unicode_source_kind=UTF-8 --allow_managed  -arch compute_52 -m64 --no-version-ident -ftz=0 -prec_div=1 -prec_sqrt=1 -fmad=1 --include_file_name "CALC.fatbin.c" -tused --gen_module_id_file --module_id_file_name "CALC.module_id" --gen_c_file_name "CALC.cudafe1.c" --stub_file_name "CALC.cudafe1.stub.c" --gen_device_file_name "CALC.cudafe1.gpu"  "CALC.cpp1.ii" -o "CALC.ptx"
#$ ptxas -arch=sm_52 -m64 "CALC.ptx"  -o "CALC.sm_52.cubin" 
#$ fatbinary --create="CALC.fatbin" -64 --cicc-cmdline="-ftz=0 -prec_div=1 -prec_sqrt=1 -fmad=1 " "--image3=kind=elf,sm=52,file=CALC.sm_52.cubin" "--image3=kind=ptx,sm=52,file=CALC.ptx" --embedded-fatbin="CALC.fatbin.c" 
#$ clang-14 -std=c++11 -D__CUDA_ARCH_LIST__=520 -E -x c++ -D__CUDACC__ -D__NVCC__  -march=core-avx2 -I"../../include/"  -D__CUDACC_VER_MAJOR__=11 -D__CUDACC_VER_MINOR__=8 -D__CUDACC_VER_BUILD__=89 -D__CUDA_API_VER_MAJOR__=11 -D__CUDA_API_VER_MINOR__=8 -D__NVCC_DIAG_PRAGMA_SUPPORT__=1 -include "cuda_runtime.h" -m64 "CALC.cu" -o "CALC.cpp4.ii" 
#$ cudafe++ --c++11 --clang --clang_version=140000 --display_error_number --orig_src_file_name "CALC.cu" --orig_src_path_name "CUDA/CALC.cu" --unicode_source_kind=UTF-8 --allow_managed --m64 --parse_templates --gen_c_file_name "CALC.cudafe1.cpp" --stub_file_name "CALC.cudafe1.stub.c" --module_id_file_name "CALC.module_id" "CALC.cpp4.ii" 

#$ clang-14 -std=c++11 -D__CUDA_ARCH__=520 -D__CUDA_ARCH_LIST__=520 -c -x c++  -DCUDA_DOUBLE_MATH_FUNCTIONS -march=core-avx2 -I"../../include/" -m64 "CALC.cudafe1.cpp" -o "CALC.o" 

```

### Program output:

```
Hello, World!
0 0 0
1 2 0
2 4 0
3 6 0
4 8 0
5 10 0
6 12 0
7 14 0
8 16 0
9 18 0
10 20 0
11 22 0
12 24 0
13 26 0
14 28 0
15 30 0
16 32 0
17 34 0
18 36 0
19 38 0
20 40 0
21 42 0
22 44 0
23 46 0
24 48 0
25 50 0
26 52 0
27 54 0
28 56 0
29 58 0
30 60 0
31 62 0
32 64 0
33 66 0
34 68 0
35 70 0
36 72 0
37 74 0
38 76 0
39 78 0
40 80 0
41 82 0
42 84 0
43 86 0
44 88 0
45 90 0
46 92 0
47 94 0
48 96 0
49 98 0
50 100 0
51 102 0
52 104 0
53 106 0
54 108 0
55 110 0
56 112 0
57 114 0
58 116 0
59 118 0
60 120 0
61 122 0
62 124 0
63 126 0
64 128 0
65 130 0
66 132 0
67 134 0
68 136 0
69 138 0
70 140 0
71 142 0
72 144 0
73 146 0
74 148 0
75 150 0
76 152 0
77 154 0
78 156 0
79 158 0
80 160 0
81 162 0
82 164 0
83 166 0
84 168 0
85 170 0
86 172 0
87 174 0
88 176 0
89 178 0
90 180 0
91 182 0
92 184 0
93 186 0
94 188 0
95 190 0
96 192 0
97 194 0
98 196 0
99 198 0
100 200 0
101 202 0
102 204 0
103 206 0
104 208 0
105 210 0
106 212 0
107 214 0
108 216 0
109 218 0
110 220 0
111 222 0
112 224 0
113 226 0
114 228 0
115 230 0
116 232 0
117 234 0
118 236 0
119 238 0
120 240 0
121 242 0
122 244 0
123 246 0
124 248 0
125 250 0
126 252 0
127 254 0
128 256 0
129 258 0
130 260 0
131 262 0
132 264 0
133 266 0
134 268 0
135 270 0
136 272 0
137 274 0
138 276 0
139 278 0
140 280 0
141 282 0
142 284 0
143 286 0
144 288 0
145 290 0
146 292 0
147 294 0
148 296 0
149 298 0
150 300 0
151 302 0
152 304 0
153 306 0
154 308 0
155 310 0
156 312 0
157 314 0
158 316 0
159 318 0
160 320 0
161 322 0
162 324 0
163 326 0
164 328 0
165 330 0
166 332 0
167 334 0
168 336 0
169 338 0
170 340 0
171 342 0
172 344 0
173 346 0
174 348 0
175 350 0
176 352 0
177 354 0
178 356 0
179 358 0
180 360 0
181 362 0
182 364 0
183 366 0
184 368 0
185 370 0
186 372 0
187 374 0
188 376 0
189 378 0
190 380 0
191 382 0
192 384 0
193 386 0
194 388 0
195 390 0
196 392 0
197 394 0
198 396 0
199 398 0
200 400 0
201 402 0
202 404 0
203 406 0
204 408 0
205 410 0
206 412 0
207 414 0
208 416 0
209 418 0
210 420 0
211 422 0
212 424 0
213 426 0
214 428 0
215 430 0
216 432 0
217 434 0
218 436 0
219 438 0
220 440 0
221 442 0
222 444 0
223 446 0
224 448 0
225 450 0
226 452 0
227 454 0
228 456 0
229 458 0
230 460 0
231 462 0
232 464 0
233 466 0
234 468 0
235 470 0
236 472 0
237 474 0
238 476 0
239 478 0
240 480 0
241 482 0
242 484 0
243 486 0
244 488 0
245 490 0
246 492 0
247 494 0
248 496 0
249 498 0
250 500 0
251 502 0
252 504 0
253 506 0
254 508 0
255 510 0
CUDA kernel executed successfully
Running AADC
0 0 0 1 0
1 2 2.48258 2.48258 -1.03312
2 4 0.938328 0.469164 -0.613332
3 6 2.26868 0.756226 2.17832
4 8 10.758 2.68951 -1.56529
5 10 2.90205 0.58041 -2.43503
6 12 3.50849 0.584749 2.96066
7 14 18.8501 2.69287 2.57751
8 16 5.99867 0.749834 -5.74469
9 18 4.2471 0.4719 2.80443
10 20 24.9165 2.49165 10.168
11 22 10.9031 0.991188 -10.9026
12 24 4.8517 0.404308 2.05799
13 26 27.8688 2.14375 18.0289
14 28 18.3561 1.31115 -17.6697
15 30 5.58463 0.372309 0.861438
16 32 27.7716 1.73573 23.1678
17 34 28.8554 1.69737 -24.4858
18 36 6.67649 0.370916 -0.854349
19 38 25.5544 1.34497 24.4063
20 40 42.1336 2.10668 -28.1005
21 42 8.39806 0.399908 -3.3591
22 44 22.3929 1.01786 22.3894
23 46 56.6721 2.46401 -24.4924
24 48 11.1317 0.463822 -7.12591
25 50 19.2306 0.769223 18.5568
26 52 69.7365 2.68217 -11.3664
27 54 15.4413 0.571901 -12.8056
28 56 16.6208 0.593599 14.1812
29 58 78.2703 2.69898 9.32827
30 60 22.1179 0.737263 -21.0654
31 62 14.8027 0.477505 9.96969
32 64 80.2994 2.50936 31.4659
33 66 32.1353 0.973798 -32.124
34 68 13.852 0.407413 6.09688
35 70 75.8865 2.16819 48.0604
36 72 46.402 1.28894 -44.8824
37 74 13.8152 0.373385 2.37231
38 76 66.9331 1.7614 55.1751
39 78 65.2053 1.67193 -55.9333
40 80 14.8054 0.370135 -1.63433
41 82 56.0812 1.36783 53.2591
42 84 87.4319 2.08171 -59.4557
43 86 17.0772 0.397143 -6.55248
44 88 45.5854 1.03603 45.5569
45 90 110.02 2.44488 -49.2969
46 92 21.0979 0.458651 -13.2167
47 94 36.7778 0.782507 35.6546
48 96 128.354 2.67403 -23.1589
49 98 27.6172 0.563616 -22.6264
50 100 30.1341 0.602682 25.9852
51 102 137.917 2.70426 14.0104
52 104 37.6985 0.724972 -35.6955
53 106 25.6143 0.483288 17.5838
54 108 136.429 2.52646 51.2303
55 110 52.6197 0.956722 -52.5682
56 112 22.9968 0.410658 10.4858
57 114 124.965 2.19236 77.4182
58 116 73.4867 1.26701 -71.3991
59 118 22.1002 0.374579 4.17979
60 120 107.228 1.78713 87.3029
61 122 100.443 1.6466 -87.0604
62 124 22.9071 0.36947 -2.12523
63 126 87.6302 1.39096 82.7215
64 128 131.62 2.05657 -91.1991
65 130 25.6433 0.394512 -9.41855
66 132 69.5982 1.05452 69.5
67 134 162.49 2.42523 -75.3676
68 136 30.8481 0.453648 -18.8959
69 138 54.9297 0.796083 53.4822
70 140 186.557 2.66509 -36.9034
71 142 39.4441 0.555551 -31.9107
72 144 44.0641 0.612001 38.3863
73 146 197.735 2.7087 16.6017
74 148 52.7589 0.712958 -49.6475
75 150 36.6939 0.489253 25.6583
76 152 193.263 2.54294 69.3901
77 154 72.3767 0.939958 -72.2379
78 156 32.2954 0.414043 15.2322
79 158 175.085 2.21627 106.019
80 160 99.6289 1.24536 -97.2008
81 162 30.4473 0.375893 6.28684
82 164 148.659 1.81291 119.488
83 166 134.576 1.6214 -117.816
84 168 30.9893 0.368921 -2.32842
85 170 120.217 1.41432 112.763
86 172 174.689 2.03127 -123.252
87 174 34.1051 0.392012 -11.963
88 176 94.4517 1.07332 94.215
89 178 214.05 2.40506 -102.624
90 180 40.393 0.448811 -24.1736
91 182 73.7056 0.809951 72.0497
92 184 244.294 2.65537 -52.5561
93 186 50.9363 0.547702 -40.6715
94 188 58.4266 0.621559 51.398
95 190 257.669 2.71231 17.0852
96 192 67.3168 0.701217 -62.9338
97 194 48.054 0.495402 34.2046
98 196 250.76 2.55878 85.877
99 198 91.427 0.923505 -91.1371
100 200 41.7572 0.417572 20.3436
101 202 226.227 2.23987 133.778
102 204 124.848 1.224 -122.271
103 206 38.8647 0.377327 8.69677
104 208 191.227 1.83872 151.665
105 210 167.617 1.59635 -148.152
106 212 39.0597 0.368488 -2.24486
107 214 153.858 1.43792 143.351
108 216 216.63 2.00583 -155.537
109 218 42.4711 0.389643 -14.1912
110 220 120.167 1.09242 119.696
111 222 264.669 2.38441 -130.984
112 224 49.7434 0.444138 -29.0593
113 226 93.1251 0.824116 91.3661
114 228 301.516 2.64487 -70.0687
115 230 62.1076 0.540066 -48.9219
116 232 73.2379 0.631361 65.034
117 234 317.663 2.71507 15.4491
118 236 81.39 0.689746 -75.5674
119 238 59.7069 0.501739 43.2348
120 240 308.875 2.57396 100.626
121 242 109.791 0.907364 -109.271
122 244 51.3921 0.421247 25.8282
123 246 278.368 2.26316 160.612
124 248 149.162 1.20292 -146.594
125 250 47.3604 0.378883 11.4133
126 252 234.932 1.86454 183.766
127 254 199.574 1.57145 -178.024
128 256 47.1259 0.368171 -1.87517
129 258 188.566 1.46175 174.449
130 260 257.437 1.98028 -187.979
131 262 50.7497 0.387402 -16.108
132 264 146.763 1.11184 145.936
133 266 314.317 2.36329 -160.366
134 268 58.9096 0.439624 -33.5623
135 270 113.208 0.838579 111.44
136 272 358.171 2.63361 -89.3886
137 274 72.9715 0.532639 -56.6746
138 276 88.5146 0.64141 79.3077
139 278 377.66 2.71698 11.6867
140 280 94.9958 0.678542 -87.5614
141 282 71.6655 0.508266 52.7611
142 284 367.562 2.58846 113.574
143 286 127.489 0.891531 -126.646
144 288 61.2099 0.425069 31.6942
145 290 331.484 2.2861 186.436
146 292 172.592 1.18214 -170.159
147 294 55.9424 0.380561 14.4405
148 296 279.772 1.89035 215.721
149 298 230.462 1.54672 -207.388
150 300 55.1954 0.367969 -1.21963
151 302 224.356 1.4858 206.019
152 304 297.106 1.95464 -220.504
153 306 58.9492 0.385289 -17.718
154 308 174.261 1.13157 172.925
155 310 362.967 2.34172 -190.684
156 312 67.9019 0.435269 -37.6916
157 314 133.975 0.853344 132.279
158 316 414.214 2.62161 -110.459
159 318 83.5415 0.525418 -63.9422
160 320 104.274 0.65171 94.2326
161 322 437.605 2.71804 5.79678
162 324 108.151 0.667601 -98.9293
163 326 83.9431 0.514988 62.7959
164 328 426.773 2.60227 124.665
165 330 144.541 0.876007 -143.269
166 332 71.2207 0.42904 37.9506
167 334 385.548 2.30867 211.166
168 336 195.158 1.16166 -192.955
169 338 64.6191 0.382361 17.7827
170 340 325.743 1.91614 247.457
171 342 260.292 1.52217 -236.204
172 344 63.2759 0.367883 -0.278133
173 346 261.239 1.51005 238.02
174 348 335.633 1.92893 -253.041
175 350 67.0778 0.383302 -19.0255
176 352 202.681 1.1516 200.652
177 354 410.594 2.31974 -221.855
178 356 76.7303 0.431069 -41.4556
179 358 155.446 0.868411 153.891
180 360 469.596 2.60887 -133.22
181 362 93.8303 0.518399 -70.737
182 364 120.532 0.662264 109.822
183 366 497.441 2.71825 -2.21652
184 368 120.873 0.656919 -109.684
185 370 96.5529 0.521907 73.352
186 372 486.459 2.61537 133.842
187 374 160.967 0.860788 -159.148
188 376 81.4348 0.433164 44.6063
189 378 440.532 2.33086 234.719
190 380 216.88 1.14148 -214.973
191 382 73.3987 0.384286 21.4447
192 384 372.841 1.94188 278.899
193 386 289.079 1.49782 -264.436
194 388 71.3749 0.367912 0.949778
195 390 299.229 1.53451 270.407
196 392 373.019 1.90316 -285.521
197 394 75.1436 0.381439 -20.0343
198 396 232.042 1.17193 229.103
199 398 457.173 2.29735 -253.795
200 400 85.4044 0.427022 -44.8626
201 402 177.64 0.883783 176.28
202 404 524.272 2.59541 -157.607
203 406 103.851 0.51158 -77.0711
204 408 137.307 0.673076 126.089
205 410 557.111 2.71761 -12.3438
206 412 133.178 0.646494 -119.84
207 414 109.509 0.529028 84.4421
208 416 546.571 2.62774 141.055
209 418 176.788 0.845874 -174.293
210 420 91.8628 0.437442 51.6709
211 422 496.406 2.35263 257.011
212 424 237.779 1.1216 -236.208
213 426 82.2898 0.386337 25.4318
214 428 421.058 1.96756 309.971
215 430 316.838 1.47367 -292.05
216 432 79.5002 0.368056 2.46492
217 434 338.335 1.55915 303.134
218 436 409.264 1.87736 -317.877
219 438 83.1545 0.379701 -20.7479
220 440 262.364 1.19256 258.264
221 442 502.685 2.27459 -286.417
222 444 93.934 0.423126 -47.9205
223 446 200.58 0.899463 199.451
224 448 578.199 2.58125 -183.554
225 450 113.615 0.504956 -82.9564
226 452 154.618 0.684149 143.046
227 454 616.56 2.71612 -24.5705
228 456 145.081 0.636321 -129.411
229 458 122.825 0.536352 96.0795
230 460 607.056 2.63938 146.258
231 462 192.021 0.831261 -188.714
232 464 102.515 0.441876 59.1541
233 466 553.137 2.37398 277.961
234 468 257.874 1.10203 -256.655
235 470 91.3008 0.388514 29.7493
236 472 470.385 1.99316 340.595
237 474 343.586 1.44973 -319.013
238 476 87.6592 0.368316 4.26845
239 478 378.567 1.58396 336.151
240 480 444.369 1.85154 -350.044
241 482 91.1184 0.378085 -21.1695
242 484 293.665 1.21349 288.115
243 486 547.109 2.25148 -319.639
244 488 102.328 0.419379 -50.6368
245 490 224.285 0.915451 223.409
246 492 631.335 2.5664 -210.988
247 494 123.136 0.498525 -88.4044
248 496 172.481 0.695487 160.706
249 498 675.732 2.71378 -38.8766
250 500 156.599 0.626396 -138.41
251 502 136.515 0.543884 108.277
252 504 667.864 2.65025 149.409
253 506 206.688 0.816948 -202.42
254 508 113.403 0.44647 67.0661
255 510 610.69 2.39486 297.489
CALC() = 0
```